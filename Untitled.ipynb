{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6627251-c075-436f-8f0f-4bef9b9a24be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: Этот ментор просто ужасен, никому не советую!\n",
      "Тональность: отрицательный\n",
      "\n",
      "Текст: Неплохой ментор, но есть и лучше.\n",
      "Тональность: нейтральный\n",
      "\n",
      "Текст: Очень доволен покупкой, всё отлично объясняет!\n",
      "Тональность: положительный\n",
      "\n",
      "Текст: Если честно, то просто отвратительный ментор, плохо объясняет алгоритмы\n",
      "Тональность: отрицательный\n",
      "\n",
      "Текст: Слабенький ментор, но для новчиков подойдет я думаю\n",
      "Тональность: нейтральный\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentAnalyzer()\n",
    "    \n",
    "# Примеры текстов для анализа\n",
    "texts = [\n",
    "        \"Этот ментор просто ужасен, никому не советую!\",\n",
    "        \"Неплохой ментор, но есть и лучше.\",\n",
    "        \"Очень доволен покупкой, всё отлично объясняет!\",\n",
    "        \"Если честно, то просто отвратительный ментор, плохо объясняет алгоритмы\",\n",
    "        \"Слабенький ментор, но для новчиков подойдет я думаю\"\n",
    "]\n",
    "    \n",
    "# Анализ тональности\n",
    "for text in texts:\n",
    "    sentiment = analyzer.predict_sentiment(text)\n",
    "    print(f\"Текст: {text}\")\n",
    "    print(f\"Тональность: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e447d6e9-f2dd-479b-8675-2cc9f31aba5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Артур\\AppData\\Local\\Temp\\ipykernel_15392\\549865934.py:114: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('train_data.csv', sep='---')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель не найдена. Начинаю обучение...\n",
      "Начало обучения модели...\n",
      "Эпоха 1/100, Потери: 129.2820\n",
      "Эпоха 2/100, Потери: 89.3988\n",
      "Эпоха 3/100, Потери: 46.3339\n",
      "Эпоха 4/100, Потери: 49.4351\n",
      "Эпоха 5/100, Потери: 48.3419\n",
      "Эпоха 6/100, Потери: 23.4589\n",
      "Эпоха 7/100, Потери: 28.4457\n",
      "Эпоха 8/100, Потери: 26.9993\n",
      "Эпоха 9/100, Потери: 14.6180\n",
      "Эпоха 10/100, Потери: 7.9652\n",
      "Эпоха 11/100, Потери: 10.7482\n",
      "Эпоха 12/100, Потери: 19.5937\n",
      "Эпоха 13/100, Потери: 4.0111\n",
      "Эпоха 14/100, Потери: 4.9320\n",
      "Эпоха 15/100, Потери: 11.8351\n",
      "Эпоха 16/100, Потери: 5.2120\n",
      "Эпоха 17/100, Потери: 1.3774\n",
      "Эпоха 18/100, Потери: 8.9101\n",
      "Эпоха 19/100, Потери: 14.3357\n",
      "Эпоха 20/100, Потери: 10.1689\n",
      "Эпоха 21/100, Потери: 5.1312\n",
      "Эпоха 22/100, Потери: 1.9481\n",
      "Эпоха 23/100, Потери: 6.2204\n",
      "Эпоха 24/100, Потери: 1.5067\n",
      "Эпоха 25/100, Потери: 11.3549\n",
      "Эпоха 26/100, Потери: 14.2219\n",
      "Эпоха 27/100, Потери: 5.0997\n",
      "Эпоха 28/100, Потери: 2.0651\n",
      "Эпоха 29/100, Потери: 6.5086\n",
      "Эпоха 30/100, Потери: 0.7221\n",
      "Эпоха 31/100, Потери: 0.5241\n",
      "Эпоха 32/100, Потери: 0.1919\n",
      "Эпоха 33/100, Потери: 9.8315\n",
      "Эпоха 34/100, Потери: 5.6413\n",
      "Эпоха 35/100, Потери: 1.3609\n",
      "Эпоха 36/100, Потери: 0.9179\n",
      "Эпоха 37/100, Потери: 8.0059\n",
      "Эпоха 38/100, Потери: 0.4741\n",
      "Эпоха 39/100, Потери: 9.2709\n",
      "Эпоха 40/100, Потери: 1.6410\n",
      "Эпоха 41/100, Потери: 0.3201\n",
      "Эпоха 42/100, Потери: 0.6343\n",
      "Эпоха 43/100, Потери: 7.0008\n",
      "Эпоха 44/100, Потери: 2.5381\n",
      "Эпоха 45/100, Потери: 1.5719\n",
      "Эпоха 46/100, Потери: 0.9096\n",
      "Эпоха 47/100, Потери: 0.3106\n",
      "Эпоха 48/100, Потери: 14.0590\n",
      "Эпоха 49/100, Потери: 0.5887\n",
      "Эпоха 50/100, Потери: 0.4600\n",
      "Эпоха 51/100, Потери: 0.1459\n",
      "Эпоха 52/100, Потери: 5.9767\n",
      "Эпоха 53/100, Потери: 2.7210\n",
      "Эпоха 54/100, Потери: 0.1547\n",
      "Эпоха 55/100, Потери: 5.5367\n",
      "Эпоха 56/100, Потери: 0.2605\n",
      "Эпоха 57/100, Потери: 0.1551\n",
      "Эпоха 58/100, Потери: 0.1517\n",
      "Эпоха 59/100, Потери: 0.6343\n",
      "Эпоха 60/100, Потери: 2.2667\n",
      "Эпоха 61/100, Потери: 5.8927\n",
      "Эпоха 62/100, Потери: 1.3888\n",
      "Эпоха 63/100, Потери: 5.7715\n",
      "Эпоха 64/100, Потери: 3.5651\n",
      "Эпоха 65/100, Потери: 6.3425\n",
      "Эпоха 66/100, Потери: 3.9256\n",
      "Эпоха 67/100, Потери: 0.8936\n",
      "Эпоха 68/100, Потери: 0.8117\n",
      "Эпоха 69/100, Потери: 2.0144\n",
      "Эпоха 70/100, Потери: 0.0960\n",
      "Эпоха 71/100, Потери: 0.1134\n",
      "Эпоха 72/100, Потери: 0.7677\n",
      "Эпоха 73/100, Потери: 6.2181\n",
      "Эпоха 74/100, Потери: 8.8842\n",
      "Эпоха 75/100, Потери: 12.5690\n",
      "Эпоха 76/100, Потери: 0.3958\n",
      "Эпоха 77/100, Потери: 1.2853\n",
      "Эпоха 78/100, Потери: 0.2051\n",
      "Эпоха 79/100, Потери: 0.1708\n",
      "Эпоха 80/100, Потери: 0.1394\n",
      "Эпоха 81/100, Потери: 0.5740\n",
      "Эпоха 82/100, Потери: 0.2551\n",
      "Эпоха 83/100, Потери: 0.5637\n",
      "Эпоха 84/100, Потери: 0.0313\n",
      "Эпоха 85/100, Потери: 0.0525\n",
      "Эпоха 86/100, Потери: 0.1440\n",
      "Эпоха 87/100, Потери: 0.0261\n",
      "Эпоха 88/100, Потери: 0.4390\n",
      "Эпоха 89/100, Потери: 1.8147\n",
      "Эпоха 90/100, Потери: 0.0581\n",
      "Эпоха 91/100, Потери: 12.2584\n",
      "Эпоха 92/100, Потери: 0.1921\n",
      "Эпоха 93/100, Потери: 0.0915\n",
      "Эпоха 94/100, Потери: 2.9247\n",
      "Эпоха 95/100, Потери: 3.7914\n",
      "Эпоха 96/100, Потери: 0.0842\n",
      "Эпоха 97/100, Потери: 0.1404\n",
      "Эпоха 98/100, Потери: 0.0316\n",
      "Эпоха 99/100, Потери: 0.1627\n",
      "Эпоха 100/100, Потери: 0.1462\n",
      "Обучение завершено.\n",
      "Модель и словарь сохранены.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите отзыв:  \"Очень доволен покупкой, всё отлично объясняет!\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тональность: положительный\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"ru_core_news_sm\")\n",
    "except OSError:\n",
    "    print(\"Пожалуйста, запустите: python -m spacy download ru_core_news_sm\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return [token.text.lower() for token in nlp(text) if not token.is_punct and not token.is_space]\n",
    "\n",
    "\n",
    "def build_vocab(corpus):\n",
    "    word_to_idx = {\"<unk>\": 0, \"<pad>\": 1}\n",
    "    idx = 2\n",
    "    for text in corpus:\n",
    "        for word in tokenize_text(text):\n",
    "            if word not in word_to_idx:\n",
    "                word_to_idx[word] = idx\n",
    "                idx += 1\n",
    "    return word_to_idx\n",
    "\n",
    "\n",
    "def text_to_sequence(text, word_to_idx, max_len=None):\n",
    "    tokens = tokenize_text(text)\n",
    "    sequence = [word_to_idx.get(word, word_to_idx[\"<unk>\"]) for word in tokens]\n",
    "    \n",
    "    if max_len:\n",
    "        if len(sequence) > max_len:\n",
    "            sequence = sequence[:max_len]\n",
    "        else:\n",
    "            sequence = sequence + [word_to_idx[\"<pad>\"]] * (max_len - len(sequence))\n",
    "    return sequence\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=2, bidirectional=False, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=True) \n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text)) \n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden_final = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        else:\n",
    "            hidden_final = self.dropout(hidden.squeeze(0)) # [batch size, hidden_dim]\n",
    "            \n",
    "        return self.fc(hidden_final)\n",
    "\n",
    "\n",
    "def train_model(model, train_data, word_to_idx, num_epochs=10, max_len=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    label_map = {\"отрицательный\": 0, \"нейтральный\": 1, \"положительный\": 2}\n",
    "\n",
    "    print(\"Начало обучения модели...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for text, label_str in train_data:\n",
    "            label = label_map[label_str]\n",
    "\n",
    "            sequence = text_to_sequence(text, word_to_idx, max_len=max_len)\n",
    "\n",
    "            input_tensor = torch.tensor(sequence).long().unsqueeze(0)\n",
    "            target_tensor = torch.tensor([label]).long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_tensor)\n",
    "            \n",
    "            loss = criterion(output, target_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        print(f\"Эпоха {epoch+1}/{num_epochs}, Потери: {total_loss:.4f}\")\n",
    "    print(\"Обучение завершено.\")\n",
    "\n",
    "    torch.save(model.state_dict(), 'sentiment_model.pt')\n",
    "\n",
    "    joblib.dump(word_to_idx, 'word_to_idx.pkl')\n",
    "    print(\"Модель и словарь сохранены.\")\n",
    "\n",
    "\n",
    "def classify_review(review, model, word_to_idx, max_len=20):\n",
    "\n",
    "    if model is None or word_to_idx is None:\n",
    "        return \"Модель не обучена или не загружена.\"\n",
    "\n",
    "    label_map_inv = {0: \"отрицательный\", 1: \"нейтральный\", 2: \"положительный\"}\n",
    "\n",
    "    sequence = text_to_sequence(review, word_to_idx, max_len=max_len)\n",
    "    input_tensor = torch.tensor(sequence).long().unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        sentiment_index = predicted.item()\n",
    "\n",
    "    return label_map_inv[sentiment_index]\n",
    "\n",
    "def main():\n",
    "    # Загружаем данные для обучения из CSV файла\n",
    "    try:\n",
    "        df = pd.read_csv('train_data.csv', sep='---')\n",
    "        train_data = list(zip(df['text'], df['sentiment']))\n",
    "    except FileNotFoundError:\n",
    "        print(\"Пожалуйста, убедитесь, что файл существует и находится в той же директории.\")\n",
    "        exit()\n",
    "\n",
    "    embedding_dim = 100\n",
    "    hidden_dim = 128 \n",
    "    output_dim = 3 \n",
    "    max_len = 40\n",
    "    num_epochs = 100 \n",
    "    n_layers = 2 \n",
    "    bidirectional = True \n",
    "    dropout = 0.5 \n",
    "\n",
    "    model_path = 'sentiment_model.pt'\n",
    "    vocab_path = 'word_to_idx.pkl'\n",
    "    \n",
    "    model = None\n",
    "    word_to_idx = None\n",
    "    \n",
    "    try:\n",
    "        word_to_idx = joblib.load(vocab_path)\n",
    "        vocab_size = len(word_to_idx)\n",
    "        \n",
    "        model = SentimentClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        print(\"Обученная модель и словарь загружены.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Модель не найдена. Начинаю обучение...\")\n",
    "        corpus = [text for text, _ in train_data]\n",
    "        word_to_idx = build_vocab(corpus)\n",
    "        vocab_size = len(word_to_idx)\n",
    "\n",
    "        model = SentimentClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout)\n",
    "        train_model(model, train_data, word_to_idx, num_epochs=num_epochs, max_len=max_len)\n",
    "        model.eval() \n",
    "\n",
    "    review = input(\"Введите отзыв: \")\n",
    "    sentiment = classify_review(review, model, word_to_idx, max_len=max_len)\n",
    "    print(f\"Тональность: {sentiment}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55080f9e-c1f3-435e-8830-630f77ca2c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
